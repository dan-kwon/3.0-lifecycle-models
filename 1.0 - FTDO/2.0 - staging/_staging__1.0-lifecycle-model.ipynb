{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "df2954df-bf65-4230-a098-57ddf137c043",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Lifecycle Model - FT Conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "833598e2-bb16-4ecd-8df0-62a77cfff9a6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Libraries / Global Vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "769fe13c-ecf8-46e5-b775-fd7380895e56",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# general use\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from chaya_ai.chaya_ai import tracker \n",
    "\n",
    "# data retrieval / prep\n",
    "from datetime import datetime\n",
    "from pyspark.sql import functions as F\n",
    "from sklearn.utils import resample\n",
    "from imblearn.over_sampling import SMOTENC, RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import gender_guesser.detector as g\n",
    "\n",
    "# pipeline\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn import set_config\n",
    "\n",
    "# feature processing and selection\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, PolynomialFeatures\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectFromModel, SelectKBest, chi2\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# training\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "# validation\n",
    "from sklearn.calibration import CalibrationDisplay, calibration_curve\n",
    "from sklearn.metrics import classification_report, PrecisionRecallDisplay\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "# matching / evaluation\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy import stats\n",
    "import random\n",
    "\n",
    "# global vars\n",
    "today = datetime.today()\n",
    "random_state = 1234"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7bc1506b-1fc9-40cf-90df-4f850ae3a848",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Loading additional UDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0ddb260e-4d6d-4f98-a091-ea88020fd9e0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run \"./udf/staging__lifecycle-features\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "14f21d77-0d6e-4b2a-bf70-8ebba6c45f96",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run \"./udf/staging__lifecycle-target-events\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2e4f640e-7776-4a44-9b17-e1964444edb9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run \"./udf/staging__lifecycle-user-cohorts\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3dd0cfa2-0c75-432a-90e1-00e93e93f095",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Creating widgets and assigning parameter values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2505887f-81c6-4351-9cc2-fdb8a6a2e662",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "  select distinct signup_date\n",
    "  from ds_staging.features__engagement_first_7_days\n",
    "  order by 1\n",
    "  \"\"\"\n",
    "\n",
    "list_of_available_dates = [str(i.date()) for i in pd.to_datetime(spark.sql(query).toPandas().values[:,0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8d26b742-984f-4ece-be97-47dac9ab4d69",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# define date range\n",
    "dbutils.widgets.dropdown(name=\"signup_date\",\n",
    "                         defaultValue=max(list_of_available_dates), \n",
    "                         choices=list_of_available_dates,\n",
    "                         label=\"Signup Date\")\n",
    "# define cohort\n",
    "dbutils.widgets.dropdown(name=\"user_cohort\", \n",
    "                         defaultValue=\"free trial drop out\", \n",
    "                         choices=[\"free trial drop out\",\"winback\"],\n",
    "                         label=\"User Cohort\")\n",
    "# define event of interest\n",
    "dbutils.widgets.dropdown(name=\"target_event\", \n",
    "                         defaultValue=\"converted free trial drop out\", \n",
    "                         choices=[\"converted free trial drop out\",\"converted winback\"],\n",
    "                         label=\"Event of Interest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3b761f17-2dbf-4c28-aa1f-762e935790b3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "USER_COHORT = dbutils.widgets.get(\"user_cohort\")\n",
    "TARGET_EVENT = dbutils.widgets.get(\"target_event\")\n",
    "SUBSCRIPTION_TYPE = 'b2c'\n",
    "COUNTRY_CODE = 'us'\n",
    "HORIZON_DAYS = 42\n",
    "\n",
    "# date parameters\n",
    "SIGNUP_DATE  = dbutils.widgets.get(\"signup_date\")\n",
    "TEST_END_DATE   = pd.to_datetime(dbutils.widgets.get(\"signup_date\")).date()-pd.to_timedelta(HORIZON_DAYS+1, unit='d')\n",
    "TEST_BEGIN_DATE = pd.to_datetime(dbutils.widgets.get(\"signup_date\")).date()-pd.to_timedelta(HORIZON_DAYS+28, unit='d')\n",
    "TRAIN_END_DATE   = pd.to_datetime(dbutils.widgets.get(\"signup_date\")).date()-pd.to_timedelta(HORIZON_DAYS+29, unit='d')\n",
    "TRAIN_BEGIN_DATE = pd.to_datetime(dbutils.widgets.get(\"signup_date\")).date()-pd.to_timedelta(HORIZON_DAYS+29+365, unit='d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b431549f-08ed-410e-a4ea-908aa87c91bf",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "50e2cb4f-1348-4e35-a9ae-a35ca9b9ac67",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# pull raw data from data warehouse\n",
    "df_users = get_user_cohort(cohort=USER_COHORT, \n",
    "                           country_code=COUNTRY_CODE, \n",
    "                           subscription_type=SUBSCRIPTION_TYPE, \n",
    "                           begin_date=TRAIN_BEGIN_DATE,\n",
    "                           end_date=TEST_END_DATE).alias(\"users\")\n",
    "\n",
    "df_engagement_features = get_engagement_features(USER_COHORT,TRAIN_BEGIN_DATE,TEST_END_DATE).alias(\"engagement\")\n",
    "\n",
    "df_event_features = get_event_features(USER_COHORT,TRAIN_BEGIN_DATE,TEST_END_DATE).alias(\"events\")\n",
    "\n",
    "df_targets = get_target_event(cohort=USER_COHORT,\n",
    "                              country_code=COUNTRY_CODE, \n",
    "                              subscription_type=SUBSCRIPTION_TYPE,\n",
    "                              begin_date=TRAIN_BEGIN_DATE,\n",
    "                              end_date=TEST_END_DATE,\n",
    "                              horizon_days=HORIZON_DAYS).alias(\"target\")\n",
    "\n",
    "# join resulting dataframes\n",
    "df_all = df_users \\\n",
    "  .join(df_targets, how=\"inner\", on=[\"hs_user_id\",\"signup_date\"]) \\\n",
    "  .join(df_engagement_features, how=\"left\", on=[\"hs_user_id\",\"signup_date\"]) \\\n",
    "  .join(df_event_features, how=\"left\", on=[\"hs_user_id\",\"signup_date\"]) \\\n",
    "  .withColumn(\"plan_renewal_term_months_c\", F.expr(\"CASE WHEN plan_renewal_term_months = 1 THEN 'monthly' \" +\n",
    "                                                        \"WHEN plan_renewal_term_months = 12 THEN 'annual' \" +\n",
    "                                                        \"ELSE 'other' END\")) \\\n",
    "  .withColumn(\"max_discount_offered_c\", F.expr(\"CASE WHEN num_offers_40 > 0 THEN 40 \" +\n",
    "                                               \"WHEN num_offers_30 > 0 THEN 30 \" +\n",
    "                                               \"WHEN num_offers_20 > 0 THEN 20 \" +\n",
    "                                               \"ELSE 0 END\")) \\\n",
    "  .withColumn(\"renewal_c\", F.expr(\"CASE WHEN renewal_count > 0 THEN 'returning' ELSE 'new' END\")) \\\n",
    "  .toPandas() \\\n",
    "  .fillna(0)\n",
    "\n",
    "df_all[\"signup_date\"] = pd.to_datetime(df_all[\"signup_date\"])\n",
    "df_all[\"dt\"] = pd.to_datetime(df_all[\"dt\"])\n",
    "\n",
    "# filter on 7 and 14 day free trial users \n",
    "df_all = df_all.loc[(df_all[\"free_trial_days\"]==7)|(df_all[\"free_trial_days\"]==14)].reset_index(drop=True)\n",
    "\n",
    "# one hot encode experiment group\n",
    "enc = OneHotEncoder()\n",
    "df_enc_experiment_group = pd.DataFrame(enc.fit_transform(df_all[[\"experiment_group\"]]).toarray())\n",
    "df_enc_experiment_group.columns = enc.get_feature_names_out()\n",
    "df_all = df_all.join(df_enc_experiment_group)\n",
    "\n",
    "# aggregating daily features to weeks\n",
    "def aggregate_into_weeks(df, week_num, feature_name):\n",
    "  df[f\"week{week_num}_{feature_name}\"] = df[f\"day{range(week_num*7-7, week_num*7)[0]}_{feature_name}\"] + \\\n",
    "                                         df[f\"day{range(week_num*7-7, week_num*7)[1]}_{feature_name}\"] + \\\n",
    "                                         df[f\"day{range(week_num*7-7, week_num*7)[2]}_{feature_name}\"] + \\\n",
    "                                         df[f\"day{range(week_num*7-7, week_num*7)[3]}_{feature_name}\"] + \\\n",
    "                                         df[f\"day{range(week_num*7-7, week_num*7)[4]}_{feature_name}\"] + \\\n",
    "                                         df[f\"day{range(week_num*7-7, week_num*7)[5]}_{feature_name}\"] + \\\n",
    "                                         df[f\"day{range(week_num*7-7, week_num*7)[6]}_{feature_name}\"]\n",
    "  return df\n",
    "for i in [ i[5:] for i in df_all.filter(like='day0').columns if 'distinct' not in i ]:\n",
    "  df_all = aggregate_into_weeks(df_all,1,i)\n",
    "   \n",
    "# split treatment and control groups\n",
    "df_treatment = df_all.loc[(df_all[\"experiment_group\"]==\"TN\")|(df_all[\"experiment_group\"]==\"TR\")]\n",
    "df_control   = df_all.loc[(df_all[\"experiment_group\"]==\"CN\")|(df_all[\"experiment_group\"]==\"CR\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d7c1deaa-c86d-4ae2-8259-019882e1fdc0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# train sets\n",
    "X_train_treatment_all_col = df_treatment[df_treatment[\"signup_date\"] <= str(TRAIN_END_DATE)] \\\n",
    "  .drop([\"experiment_group\",\n",
    "         \"experiment_group_TR\",\n",
    "         \"experiment_group_TN\",\n",
    "         \"experiment_group_CR\",\n",
    "         \"experiment_group_CN\"], \n",
    "        axis=1)\n",
    "y_train_treatment = df_treatment.loc[df_treatment[\"signup_date\"] <= str(TRAIN_END_DATE),\"experiment_group_TR\"]\n",
    "\n",
    "X_train_control_all_col = df_control[df_control[\"signup_date\"] <= str(TRAIN_END_DATE)] \\\n",
    "  .drop([\"experiment_group\",\n",
    "         \"experiment_group_TR\",\n",
    "         \"experiment_group_TN\",\n",
    "         \"experiment_group_CR\",\n",
    "         \"experiment_group_CN\"], \n",
    "        axis=1)\n",
    "y_train_control = df_control.loc[df_control[\"signup_date\"] <= str(TRAIN_END_DATE),\"experiment_group_CR\"]\n",
    "\n",
    "# test sets\n",
    "X_test_all_col = df_all[df_all[\"signup_date\"] > str(TRAIN_END_DATE)] \\\n",
    "  .drop([\"experiment_group\",\n",
    "         \"experiment_group_TR\",\n",
    "         \"experiment_group_TN\",\n",
    "         \"experiment_group_CR\",\n",
    "         \"experiment_group_CN\"], \n",
    "        axis=1)\n",
    "X_test_treatment_all_col = df_treatment.loc[df_treatment[\"signup_date\"] > str(TRAIN_END_DATE)] \\\n",
    "  .drop([\"experiment_group\",\n",
    "         \"experiment_group_TR\",\n",
    "         \"experiment_group_TN\",\n",
    "         \"experiment_group_CR\",\n",
    "         \"experiment_group_CN\"], \n",
    "        axis=1)\n",
    "X_test_control_all_col = df_control[df_control[\"signup_date\"] > str(TRAIN_END_DATE)] \\\n",
    "  .drop([\"experiment_group\",\n",
    "         \"experiment_group_TR\",\n",
    "         \"experiment_group_TN\",\n",
    "         \"experiment_group_CR\",\n",
    "         \"experiment_group_CN\"], \n",
    "        axis=1)\n",
    "y_test_TR = df_all.loc[df_all[\"signup_date\"] > str(TRAIN_END_DATE), \"experiment_group_TR\"]\n",
    "y_test_CR = df_all.loc[df_all[\"signup_date\"] > str(TRAIN_END_DATE), \"experiment_group_CR\"]\n",
    "y_test_treatment = df_treatment.loc[df_treatment[\"signup_date\"] > str(TRAIN_END_DATE), \"experiment_group_TR\"]\n",
    "y_test_control = df_control.loc[df_control[\"signup_date\"] > str(TRAIN_END_DATE), \"experiment_group_CR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6bd976c7-8313-4c6b-be0e-9620fbe82aa4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# specify categorical column names\n",
    "categorical_col = [\"plan_renewal_term_months_c\", \"subscription_platform\", \"renewal_c\"] #, \"num_offers_20\", \"num_offers_30\", \"num_offers_40\"]\n",
    "\n",
    "# get list of categorical + numeric features to include in model\n",
    "X_col = categorical_col.copy()\n",
    "X_col += [i for i in X_train_treatment_all_col.columns if 'week1' in i or \n",
    "                                                          'free_trial_days' in i or\n",
    "                                                          'max_discount' in i or\n",
    "                                                          'renewal_count' in i or\n",
    "                                                          'free_trial_days' in i]\n",
    "X_col.sort()\n",
    "X_train_treatment = X_train_treatment_all_col[X_col]\n",
    "X_train_control   = X_train_control_all_col[X_col]\n",
    "X_test_treatment  = X_test_treatment_all_col[X_col]\n",
    "X_test_control    = X_test_control_all_col[X_col]\n",
    "\n",
    "X_test            = X_test_all_col[X_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2b0b0d5f-1ab0-46c7-beea-1ad77bd1a9c9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# SMOTE oversampling the minority class\n",
    "smote_oversample = SMOTENC(random_state=random_state, categorical_features=[X_train_treatment.columns.get_loc(col) for col in categorical_col])\n",
    "X_train_treatment, y_train_treatment = smote_oversample.fit_resample(X_train_treatment, y_train_treatment)\n",
    "X_train_control,   y_train_control   = smote_oversample.fit_resample(X_train_control,   y_train_control)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8e2a3193-a89f-4594-8e1b-d0efcebbe6e3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fe3dcd8d-e104-4e92-8c8e-2fe146af476d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "numeric_preprocessor = Pipeline(\n",
    "    steps=[\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"pca\", PCA()),\n",
    "        (\"variance threshold\", VarianceThreshold())\n",
    "    ])\n",
    "\n",
    "categorical_preprocessor = Pipeline(\n",
    "    steps=[\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "    ])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        (\"categorical\", categorical_preprocessor, categorical_col),\n",
    "        (\"numerical\", numeric_preprocessor, list(set(X_col) - set(categorical_col))),\n",
    "    ])\n",
    "\n",
    "pipe_rf_t = Pipeline(\n",
    "    steps=[(\"preprocessor\", preprocessor),\n",
    "           (\"interactions\", PolynomialFeatures(interaction_only=False)),\n",
    "           ('classifier', CalibratedClassifierCV(base_estimator=RandomForestClassifier(min_samples_split=0.05, n_estimators = 150), cv=5, method='sigmoid', n_jobs=20))])\n",
    "\n",
    "pipe_rf_c = Pipeline(\n",
    "    steps=[(\"preprocessor\", preprocessor),\n",
    "           (\"interactions\", PolynomialFeatures(interaction_only=False)),\n",
    "           ('classifier', CalibratedClassifierCV(base_estimator=RandomForestClassifier(min_samples_split=0.05, n_estimators = 150), cv=5, method='sigmoid', n_jobs=20))])\n",
    "\n",
    "# grid search takes ~30 min and doesn't result in a meaningful increase in performance so commenting out for now\n",
    "#pipe_rf = Pipeline(\n",
    "#    steps=[(\"preprocessor\", preprocessor),\n",
    "#           (\"interactions\", PolynomialFeatures(interaction_only=False)),\n",
    "#           ('classifier', RandomForestClassifier())\n",
    "#          ])\n",
    "#param_grid_rf = {\n",
    "#  \"classifier__n_estimators\": [200, 400, 600],\n",
    "#  \"classifier__max_depth\": [6, 8, 10, 12]\n",
    "#}\n",
    "#grid_search_rf = GridSearchCV(pipe_rf, param_grid_rf, n_jobs=20, scoring='f1_micro')\n",
    "#calibrated_clf = CalibratedClassifierCV(grid_search_rf.best_estimator_)\n",
    "#calibrated_clf.fit(X_train_smote, y_train_smote.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bfad32bd-8898-4e96-a67f-984dc5f8f95c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3202b4a8-2cfe-4ae1-8021-a065165ed5f4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# train on oversampled training set\n",
    "set_config(display=\"diagram\")\n",
    "\n",
    "# active models\n",
    "pipe_rf_t.fit(X_train_treatment, y_train_treatment.values.ravel())\n",
    "pipe_rf_c.fit(X_train_control, y_train_control.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "522e1cb3-6df3-40de-ba73-ff2656f92f86",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Testing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "131b59b2-4672-4ee6-b3af-dc0bfdc9a2a3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## test on treatment_group\n",
    "y_scores_treatment = pipe_rf_t.predict_proba(X_test_treatment)[:,1]\n",
    "y_pred_treatment = pipe_rf_t.predict(X_test_treatment)\n",
    "#### performance\n",
    "print(\"TREATMENT (imbalanced test set)\"+\"-\"*22)\n",
    "print(classification_report(y_test_treatment, y_pred_treatment))\n",
    "y_scores_treatment = pipe_rf_t.predict_proba(X_test_treatment)[:,1]\n",
    "precision, recall, thresholds = precision_recall_curve(y_test_treatment, y_scores_treatment)\n",
    "print(\"auc for RF-SMOTE: \"+str(auc(recall, precision)))\n",
    "\n",
    "## test on control_group\n",
    "y_scores_control = pipe_rf_c.predict_proba(X_test_control)[:,1]\n",
    "y_pred_control = pipe_rf_c.predict(X_test_control)\n",
    "#### performance\n",
    "print(\"CONTROL (imbalanced test set)\"+\"-\"*24)\n",
    "print(classification_report(y_test_control, y_pred_control))\n",
    "precision, recall, thresholds = precision_recall_curve(y_test_control, y_scores_control)\n",
    "print(\"auc for RF-SMOTE: \"+str(auc(recall, precision)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6beb3995-b21f-465d-9cf5-3d3fac493f4c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "#sns.lineplot(x=, y=metrics.roc_curve(y_test_treatment, y_scores_treatment))\n",
    "print(metrics.roc_auc_score(y_test_treatment, y_scores_treatment))\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test_treatment, y_scores_treatment)\n",
    "\n",
    "sns.lineplot(x=fpr, y=tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "efe395e8-6128-4ced-ac5d-9ad536253ceb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### Take Rates vs. Propensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c2117ee5-841e-4fa1-a43f-338923dbbd72",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# plotting actual vs predicted take rates\n",
    "prob_true, prob_pred = calibration_curve(y_test_treatment, y_scores_treatment, n_bins=10)\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "sns.lineplot(x=prob_pred, y=prob_true, color=\"red\", ax=ax1)\n",
    "sns.histplot(y_scores_treatment, stat=\"probability\", color='blue', alpha=0.4, ax=ax2, bins=10)\n",
    "\n",
    "ax1.set_xlabel(\"predicted propensity to respond to a discount\")\n",
    "ax1.set_ylabel(\"actual return rate\")\n",
    "ax2.set_ylabel(\"% of users\")\n",
    "plt.title(\"Predicted vs. Actual Propensities - Treatment Group\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "671ae477-154a-4aad-820e-1907172c2b56",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# plotting actual vs predicted take rates\n",
    "prob_true, prob_pred = calibration_curve(y_test_control, y_scores_control, n_bins=10)\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "sns.lineplot(x=prob_pred, y=prob_true, color=\"red\", ax=ax1)\n",
    "sns.histplot(y_scores_control, stat=\"probability\", color='blue', alpha=0.4, ax=ax2, bins=10)\n",
    "\n",
    "ax1.set_xlabel(\"predicted propensity to return without a discount\")\n",
    "ax1.set_ylabel(\"actual return rate\")\n",
    "ax2.set_ylabel(\"% of users\")\n",
    "plt.title(\"Predicted vs. Actual Propensities - Control Group\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "88f69fee-203d-4e26-8c3d-e0a6e1bd1aa5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### Distribution of Propensities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2afcebbf-ca30-44dc-bb32-577c63f31d8a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# joining back to y_test to X_test and append model predictions\n",
    "y_scores_TR = pipe_rf_t.predict_proba(X_test)[:,1]\n",
    "y_scores_CR = pipe_rf_c.predict_proba(X_test)[:,1]\n",
    "\n",
    "joined_test_set = X_test_all_col.join(y_test_TR).join(y_test_CR)\n",
    "joined_test_set[\"propensity_TR\"] = y_scores_TR.tolist()\n",
    "joined_test_set[\"propensity_CR\"] = y_scores_CR.tolist()\n",
    "joined_test_set[\"propensity_TN\"] = 1-joined_test_set[\"propensity_TR\"]\n",
    "joined_test_set[\"propensity_CN\"] = 1-joined_test_set[\"propensity_CR\"]\n",
    "joined_test_set[\"uplift_score\"] = joined_test_set[\"propensity_TR\"] + joined_test_set[\"propensity_CN\"] - joined_test_set[\"propensity_TN\"] - joined_test_set[\"propensity_CR\"]\n",
    "joined_test_set['uplift_score_bin'] = pd.qcut(joined_test_set[\"uplift_score\"], q=5, precision=0, labels=[5,4,3,2,1])\n",
    "joined_test_set['propensity_TR_bin'] = pd.qcut(joined_test_set[\"propensity_TR\"], q=5, precision=0, labels=[5,4,3,2,1])\n",
    "joined_test_set['propensity_CN_bin'] = pd.qcut(joined_test_set[\"propensity_CN\"], q=5, precision=0, labels=[5,4,3,2,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "707959fd-b35b-4bb0-ace9-8ad16be859a5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sns.histplot(joined_test_set[\"uplift_score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9a2f94fb-3881-4a97-851c-8fb58814c9f7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Scoring hold out users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1acea3d9-f057-4537-a4b4-9c7b6e97a157",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### Pulling features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a7bc6782-ceb6-4e24-854b-c983a7a28d31",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# pull raw data from data warehouse\n",
    "df_users_to_score = get_user_cohort(cohort=USER_COHORT, \n",
    "                                    country_code=COUNTRY_CODE, \n",
    "                                    subscription_type=SUBSCRIPTION_TYPE, \n",
    "                                    begin_date=SIGNUP_DATE,\n",
    "                                    end_date=SIGNUP_DATE).alias(\"users\")\n",
    "\n",
    "df_engagement_features_to_score = get_engagement_features(USER_COHORT,SIGNUP_DATE,SIGNUP_DATE).alias(\"engagement\")\n",
    "\n",
    "df_event_features_to_score = get_event_features(USER_COHORT,SIGNUP_DATE,SIGNUP_DATE).alias(\"events\")\n",
    "\n",
    "# join resulting dataframes\n",
    "df_all_to_score = df_users_to_score \\\n",
    "  .join(df_engagement_features_to_score, how=\"left\", on=[\"hs_user_id\",\"signup_date\"]) \\\n",
    "  .join(df_event_features_to_score, how=\"left\", on=[\"hs_user_id\",\"signup_date\"]) \\\n",
    "  .withColumn(\"plan_renewal_term_months_c\", F.expr(\"CASE WHEN plan_renewal_term_months = 1 THEN 'monthly' \" +\n",
    "                                                        \"WHEN plan_renewal_term_months = 12 THEN 'annual' \" +\n",
    "                                                        \"ELSE 'other' END\")) \\\n",
    "  .withColumn(\"renewal_c\", F.expr(\"CASE WHEN renewal_count > 0 THEN 'returning' ELSE 'new' END\")) \\\n",
    "  .toPandas() \\\n",
    "  .fillna(0)\n",
    "df_all_to_score[\"max_discount_offered_c\"] = 20\n",
    "df_all_to_score[\"signup_date\"] = pd.to_datetime(df_all_to_score[\"signup_date\"])\n",
    "df_all_to_score[\"dt\"] = pd.to_datetime(df_all_to_score[\"dt\"])\n",
    "\n",
    "# filter on 7 and 14 day free trial users \n",
    "df_all_to_score = df_all_to_score.loc[(df_all_to_score[\"free_trial_days\"]==7)|(df_all_to_score[\"free_trial_days\"]==14)].reset_index(drop=True)\n",
    "\n",
    "# aggregating daily features to weeks\n",
    "for i in [ i[5:] for i in df_all_to_score.filter(like='day0').columns if 'distinct' not in i ]:\n",
    "  df_all_to_score = aggregate_into_weeks(df_all_to_score,1,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "01a43c5c-03d1-4adc-9574-ef01abb153b0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X_score = df_all_to_score[X_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dfa2395c-a6d4-46dd-9ae1-f76162c48cb2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### Scoring users and appending to feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b466c863-126b-46ef-a396-4acadf784b1b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# joining back to y_test to X_test and append model predictions\n",
    "df_all_to_score[\"propensity_TR\"] = pipe_rf_t.predict_proba(X_score)[:,1].tolist()\n",
    "df_all_to_score[\"propensity_CR\"] = pipe_rf_c.predict_proba(X_score)[:,1].tolist()\n",
    "df_all_to_score[\"propensity_TN\"] = 1-df_all_to_score[\"propensity_TR\"]\n",
    "df_all_to_score[\"propensity_CN\"] = 1-df_all_to_score[\"propensity_CR\"]\n",
    "df_all_to_score[\"uplift_score\"] = df_all_to_score[\"propensity_TR\"] + df_all_to_score[\"propensity_CN\"] - df_all_to_score[\"propensity_TN\"] - df_all_to_score[\"propensity_CR\"]\n",
    "df_all_to_score['uplift_score_bin'] = pd.qcut(df_all_to_score[\"uplift_score\"], q=5, precision=0, labels=[5,4,3,2,1])\n",
    "df_all_to_score['propensity_TR_bin'] = pd.qcut(df_all_to_score[\"propensity_TR\"], q=5, precision=0, labels=[5,4,3,2,1])\n",
    "df_all_to_score['propensity_CN_bin'] = pd.qcut(df_all_to_score[\"propensity_CN\"], q=5, precision=0, labels=[5,4,3,2,1])\n",
    "df_all_to_score[\"signup_date\"] = [str(i.date()) for i in df_all_to_score[\"signup_date\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5445714c-c3c7-4e02-99e6-2fd6bb3925ae",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## Convert into Spark DataFrame\n",
    "spark_df = spark.createDataFrame(df_all_to_score[[\"hs_user_id\",\n",
    "                                                  \"signup_date\",\n",
    "                                                  \"propensity_TR\",\n",
    "                                                  \"propensity_CR\",\n",
    "                                                  \"propensity_TN\",\n",
    "                                                  \"propensity_CN\",\n",
    "                                                  \"uplift_score\",\n",
    "                                                  \"uplift_score_bin\"\n",
    "                                                 ]])\n",
    "## Write to databricks\n",
    "spark_df \\\n",
    "  .write \\\n",
    "  .mode('append') \\\n",
    "  .option(\"mergeSchema\", \"true\") \\\n",
    "  .saveAsTable(\"ds_staging.lifecycle_models__ftdo_propensity_scores\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "_staging__1.0-lifecycle-model",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
