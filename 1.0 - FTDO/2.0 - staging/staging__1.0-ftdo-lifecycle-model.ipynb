{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "33a8e356-9a30-4a36-b4d8-d4750f356e24",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Lifecycle Model - FT Conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9d648cf4-c045-4b14-b66a-07e37c60b380",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Libraries / Global Vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "96c2dde0-f017-4018-92f8-4d5ebcbfcc8f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# general use\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from chaya_ai.chaya_ai import tracker \n",
    "\n",
    "# data retrieval / prep\n",
    "from datetime import datetime\n",
    "from pyspark.sql import functions as F\n",
    "from sklearn.utils import resample\n",
    "from imblearn.over_sampling import SMOTENC, RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import gender_guesser.detector as g\n",
    "\n",
    "# pipeline\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn import set_config\n",
    "\n",
    "# feature processing and selection\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, PolynomialFeatures\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectFromModel, SelectKBest, chi2\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# training\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "# validation\n",
    "from sklearn.calibration import CalibrationDisplay, calibration_curve\n",
    "from sklearn.metrics import classification_report, PrecisionRecallDisplay\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "# matching / evaluation\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy import stats\n",
    "import random\n",
    "\n",
    "# global vars\n",
    "today = datetime.today()\n",
    "random_state = 1234"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9888d4dc-1279-417a-a719-a77c7176925c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Loading additional UDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "48001a55-a48b-4032-8140-aef7b238b6ef",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run \"./udf/prod__lifecycle-features\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1d40f361-f1a3-459f-a25d-0cecea1fcaeb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run \"./udf/prod__lifecycle-target-events\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0fa688b3-bb71-4909-b373-7bfbca776269",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run \"./udf/prod__lifecycle-user-cohorts\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "53b87976-02a9-4972-8171-7787f9c30dfa",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Creating widgets and assigning parameter values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "10eab964-91fe-44b8-bdb4-14b1c89cdd3d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "  select max(signup_date)\n",
    "  from ds_staging.features__engagement_first_7_days\n",
    "  order by 1\n",
    "  \"\"\"\n",
    "\n",
    "list_of_available_dates = [str(i.date()) for i in pd.to_datetime(spark.sql(query).toPandas().values[:,0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f638f182-59cd-4434-81f3-795f172c38c6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# define date range\n",
    "dbutils.widgets.text(name=\"signup_date\",\n",
    "                         defaultValue=max(list_of_available_dates),\n",
    "                         label=\"Signup Date\")\n",
    "# define cohort\n",
    "dbutils.widgets.text(name=\"user_cohort\", \n",
    "                         defaultValue=\"free trial drop out\", \n",
    "                         label=\"User Cohort\")\n",
    "# define event of interest\n",
    "dbutils.widgets.text(name=\"target_event\", \n",
    "                     defaultValue=\"converted free trial drop out\",\n",
    "                     label=\"Event of Interest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "263e9d7a-0f5e-4720-90d0-0d0fe74a9cf8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "USER_COHORT = dbutils.widgets.get(\"user_cohort\")\n",
    "TARGET_EVENT = dbutils.widgets.get(\"target_event\")\n",
    "SUBSCRIPTION_TYPE = 'b2c'\n",
    "COUNTRY_CODE = 'us'\n",
    "HORIZON_DAYS = 42\n",
    "\n",
    "# date parameters\n",
    "SIGNUP_DATE  = dbutils.widgets.get(\"signup_date\")\n",
    "TEST_END_DATE   = pd.to_datetime(dbutils.widgets.get(\"signup_date\")).date()-pd.to_timedelta(HORIZON_DAYS+1, unit='d')\n",
    "TEST_BEGIN_DATE = pd.to_datetime(dbutils.widgets.get(\"signup_date\")).date()-pd.to_timedelta(HORIZON_DAYS+28, unit='d')\n",
    "TRAIN_END_DATE   = pd.to_datetime(dbutils.widgets.get(\"signup_date\")).date()-pd.to_timedelta(HORIZON_DAYS+29, unit='d')\n",
    "TRAIN_BEGIN_DATE = pd.to_datetime(dbutils.widgets.get(\"signup_date\")).date()-pd.to_timedelta(HORIZON_DAYS+29+365, unit='d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4a86549c-725c-439f-9b29-b74fee8210fe",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "323a29c3-8056-4e58-ad33-f36354b9a86b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# pull raw data from data warehouse\n",
    "df_users = get_user_cohort(cohort=USER_COHORT, \n",
    "                           country_code=COUNTRY_CODE, \n",
    "                           subscription_type=SUBSCRIPTION_TYPE, \n",
    "                           begin_date=TRAIN_BEGIN_DATE,\n",
    "                           end_date=TEST_END_DATE).alias(\"users\")\n",
    "\n",
    "df_engagement_features = get_engagement_features(USER_COHORT,TRAIN_BEGIN_DATE,TEST_END_DATE).alias(\"engagement\")\n",
    "\n",
    "df_event_features = get_event_features(USER_COHORT,TRAIN_BEGIN_DATE,TEST_END_DATE).alias(\"events\")\n",
    "\n",
    "df_targets = get_target_event(cohort=USER_COHORT,\n",
    "                              country_code=COUNTRY_CODE, \n",
    "                              subscription_type=SUBSCRIPTION_TYPE,\n",
    "                              begin_date=TRAIN_BEGIN_DATE,\n",
    "                              end_date=TEST_END_DATE,\n",
    "                              horizon_days=HORIZON_DAYS).alias(\"target\")\n",
    "\n",
    "# join resulting dataframes\n",
    "df_all = df_users \\\n",
    "  .join(df_targets, how=\"inner\", on=[\"hs_user_id\",\"signup_date\"]) \\\n",
    "  .join(df_engagement_features, how=\"left\", on=[\"hs_user_id\",\"signup_date\"]) \\\n",
    "  .join(df_event_features, how=\"left\", on=[\"hs_user_id\",\"signup_date\"]) \\\n",
    "  .withColumn(\"plan_renewal_term_months_c\", F.expr(\"CASE WHEN plan_renewal_term_months = 1 THEN 'monthly' \" +\n",
    "                                                        \"WHEN plan_renewal_term_months = 12 THEN 'annual' \" +\n",
    "                                                        \"ELSE 'other' END\")) \\\n",
    "  .withColumn(\"max_discount_offered_c\", F.expr(\"CASE WHEN num_offers_40 > 0 THEN 40 \" +\n",
    "                                               \"WHEN num_offers_30 > 0 THEN 30 \" +\n",
    "                                               \"WHEN num_offers_20 > 0 THEN 20 \" +\n",
    "                                               \"ELSE 0 END\")) \\\n",
    "  .withColumn(\"renewal_c\", F.expr(\"CASE WHEN renewal_count > 0 THEN 'returning' ELSE 'new' END\")) \\\n",
    "  .toPandas() \\\n",
    "  .fillna(0)\n",
    "\n",
    "df_all[\"signup_date\"] = pd.to_datetime(df_all[\"signup_date\"])\n",
    "df_all[\"dt\"] = pd.to_datetime(df_all[\"dt\"])\n",
    "\n",
    "# filter on 7 and 14 day free trial users \n",
    "df_all = df_all.loc[(df_all[\"free_trial_days\"]==7)|(df_all[\"free_trial_days\"]==14)].reset_index(drop=True)\n",
    "\n",
    "# one hot encode experiment group\n",
    "enc = OneHotEncoder()\n",
    "df_enc_experiment_group = pd.DataFrame(enc.fit_transform(df_all[[\"experiment_group\"]]).toarray())\n",
    "df_enc_experiment_group.columns = enc.get_feature_names_out()\n",
    "df_all = df_all.join(df_enc_experiment_group)\n",
    "\n",
    "# aggregating daily features to weeks\n",
    "def aggregate_into_weeks(df, week_num, feature_name):\n",
    "  df[f\"week{week_num}_{feature_name}\"] = df[f\"day{range(week_num*7-7, week_num*7)[0]}_{feature_name}\"] + \\\n",
    "                                         df[f\"day{range(week_num*7-7, week_num*7)[1]}_{feature_name}\"] + \\\n",
    "                                         df[f\"day{range(week_num*7-7, week_num*7)[2]}_{feature_name}\"] + \\\n",
    "                                         df[f\"day{range(week_num*7-7, week_num*7)[3]}_{feature_name}\"] + \\\n",
    "                                         df[f\"day{range(week_num*7-7, week_num*7)[4]}_{feature_name}\"] + \\\n",
    "                                         df[f\"day{range(week_num*7-7, week_num*7)[5]}_{feature_name}\"] + \\\n",
    "                                         df[f\"day{range(week_num*7-7, week_num*7)[6]}_{feature_name}\"]\n",
    "  return df\n",
    "for i in [ i[5:] for i in df_all.filter(like='day0').columns if 'distinct' not in i ]:\n",
    "  df_all = aggregate_into_weeks(df_all,1,i)\n",
    "   \n",
    "# split treatment and control groups\n",
    "df_treatment = df_all.loc[(df_all[\"experiment_group\"]==\"TN\")|(df_all[\"experiment_group\"]==\"TR\")]\n",
    "df_control   = df_all.loc[(df_all[\"experiment_group\"]==\"CN\")|(df_all[\"experiment_group\"]==\"CR\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fca63fdb-9cc5-49c1-85e9-8103b95d2be6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# train sets\n",
    "X_train_treatment_all_col = df_treatment[df_treatment[\"signup_date\"] <= str(TRAIN_END_DATE)] \\\n",
    "  .drop([\"experiment_group\",\n",
    "         \"experiment_group_TR\",\n",
    "         \"experiment_group_TN\",\n",
    "         \"experiment_group_CR\",\n",
    "         \"experiment_group_CN\"], \n",
    "        axis=1)\n",
    "y_train_treatment = df_treatment.loc[df_treatment[\"signup_date\"] <= str(TRAIN_END_DATE),\"experiment_group_TR\"]\n",
    "\n",
    "X_train_control_all_col = df_control[df_control[\"signup_date\"] <= str(TRAIN_END_DATE)] \\\n",
    "  .drop([\"experiment_group\",\n",
    "         \"experiment_group_TR\",\n",
    "         \"experiment_group_TN\",\n",
    "         \"experiment_group_CR\",\n",
    "         \"experiment_group_CN\"], \n",
    "        axis=1)\n",
    "y_train_control = df_control.loc[df_control[\"signup_date\"] <= str(TRAIN_END_DATE),\"experiment_group_CR\"]\n",
    "\n",
    "# test sets\n",
    "X_test_all_col = df_all[df_all[\"signup_date\"] > str(TRAIN_END_DATE)] \\\n",
    "  .drop([\"experiment_group\",\n",
    "         \"experiment_group_TR\",\n",
    "         \"experiment_group_TN\",\n",
    "         \"experiment_group_CR\",\n",
    "         \"experiment_group_CN\"], \n",
    "        axis=1)\n",
    "X_test_treatment_all_col = df_treatment.loc[df_treatment[\"signup_date\"] > str(TRAIN_END_DATE)] \\\n",
    "  .drop([\"experiment_group\",\n",
    "         \"experiment_group_TR\",\n",
    "         \"experiment_group_TN\",\n",
    "         \"experiment_group_CR\",\n",
    "         \"experiment_group_CN\"], \n",
    "        axis=1)\n",
    "X_test_control_all_col = df_control[df_control[\"signup_date\"] > str(TRAIN_END_DATE)] \\\n",
    "  .drop([\"experiment_group\",\n",
    "         \"experiment_group_TR\",\n",
    "         \"experiment_group_TN\",\n",
    "         \"experiment_group_CR\",\n",
    "         \"experiment_group_CN\"], \n",
    "        axis=1)\n",
    "y_test_TR = df_all.loc[df_all[\"signup_date\"] > str(TRAIN_END_DATE), \"experiment_group_TR\"]\n",
    "y_test_CR = df_all.loc[df_all[\"signup_date\"] > str(TRAIN_END_DATE), \"experiment_group_CR\"]\n",
    "y_test_treatment = df_treatment.loc[df_treatment[\"signup_date\"] > str(TRAIN_END_DATE), \"experiment_group_TR\"]\n",
    "y_test_control = df_control.loc[df_control[\"signup_date\"] > str(TRAIN_END_DATE), \"experiment_group_CR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "13fe8a6e-c790-48a1-b786-9b7cd84b9605",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# specify categorical column names\n",
    "categorical_col = [\"plan_renewal_term_months_c\", \"subscription_platform\", \"renewal_c\"] #, \"num_offers_20\", \"num_offers_30\", \"num_offers_40\"]\n",
    "\n",
    "# get list of categorical + numeric features to include in model\n",
    "X_col = categorical_col.copy()\n",
    "X_col += [i for i in X_train_treatment_all_col.columns if 'week1' in i or \n",
    "                                                          'free_trial_days' in i or\n",
    "                                                          'max_discount' in i or\n",
    "                                                          'renewal_count' in i or\n",
    "                                                          'free_trial_days' in i]\n",
    "X_col.sort()\n",
    "X_train_treatment = X_train_treatment_all_col[X_col]\n",
    "X_train_control   = X_train_control_all_col[X_col]\n",
    "X_test_treatment  = X_test_treatment_all_col[X_col]\n",
    "X_test_control    = X_test_control_all_col[X_col]\n",
    "\n",
    "X_test            = X_test_all_col[X_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "60fc03cc-d08e-4a89-b6be-ef81a3cee23d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# SMOTE oversampling the minority class\n",
    "smote_oversample = SMOTENC(random_state=random_state, categorical_features=[X_train_treatment.columns.get_loc(col) for col in categorical_col])\n",
    "X_train_treatment, y_train_treatment = smote_oversample.fit_resample(X_train_treatment, y_train_treatment)\n",
    "X_train_control,   y_train_control   = smote_oversample.fit_resample(X_train_control,   y_train_control)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "716b88bf-4454-47ba-b1e2-47e7815f634f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2781879d-0119-40c7-b887-bcac2e219c36",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "numeric_preprocessor = Pipeline(\n",
    "    steps=[\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"pca\", PCA()),\n",
    "        (\"variance threshold\", VarianceThreshold())\n",
    "    ])\n",
    "\n",
    "categorical_preprocessor = Pipeline(\n",
    "    steps=[\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "    ])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        (\"categorical\", categorical_preprocessor, categorical_col),\n",
    "        (\"numerical\", numeric_preprocessor, list(set(X_col) - set(categorical_col))),\n",
    "    ])\n",
    "\n",
    "pipe_rf_t = Pipeline(\n",
    "    steps=[(\"preprocessor\", preprocessor),\n",
    "           (\"interactions\", PolynomialFeatures(interaction_only=False)),\n",
    "           ('classifier', CalibratedClassifierCV(base_estimator=RandomForestClassifier(min_samples_split=0.05, n_estimators = 150), cv=5, method='sigmoid', n_jobs=20))])\n",
    "\n",
    "pipe_rf_c = Pipeline(\n",
    "    steps=[(\"preprocessor\", preprocessor),\n",
    "           (\"interactions\", PolynomialFeatures(interaction_only=False)),\n",
    "           ('classifier', CalibratedClassifierCV(base_estimator=RandomForestClassifier(min_samples_split=0.05, n_estimators = 150), cv=5, method='sigmoid', n_jobs=20))])\n",
    "\n",
    "# grid search takes ~30 min and doesn't result in a meaningful increase in performance so commenting out for now\n",
    "#pipe_rf = Pipeline(\n",
    "#    steps=[(\"preprocessor\", preprocessor),\n",
    "#           (\"interactions\", PolynomialFeatures(interaction_only=False)),\n",
    "#           ('classifier', RandomForestClassifier())\n",
    "#          ])\n",
    "#param_grid_rf = {\n",
    "#  \"classifier__n_estimators\": [200, 400, 600],\n",
    "#  \"classifier__max_depth\": [6, 8, 10, 12]\n",
    "#}\n",
    "#grid_search_rf = GridSearchCV(pipe_rf, param_grid_rf, n_jobs=20, scoring='f1_micro')\n",
    "#calibrated_clf = CalibratedClassifierCV(grid_search_rf.best_estimator_)\n",
    "#calibrated_clf.fit(X_train_smote, y_train_smote.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e4b3c7f5-c46a-49fe-97bf-c406f2dd8028",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bb8966ad-82d0-4082-83e0-a128766cb640",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# train on oversampled training set\n",
    "set_config(display=\"diagram\")\n",
    "\n",
    "# active models\n",
    "pipe_rf_t.fit(X_train_treatment, y_train_treatment.values.ravel())\n",
    "pipe_rf_c.fit(X_train_control, y_train_control.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0bc9e9a0-676d-42fd-807a-eedc219e9998",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Testing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "45c946c5-3b2b-4d34-b859-a16b914083b2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## test on treatment_group\n",
    "y_scores_treatment = pipe_rf_t.predict_proba(X_test_treatment)[:,1]\n",
    "y_pred_treatment = pipe_rf_t.predict(X_test_treatment)\n",
    "#### performance\n",
    "print(\"TREATMENT (imbalanced test set)\"+\"-\"*22)\n",
    "print(classification_report(y_test_treatment, y_pred_treatment))\n",
    "y_scores_treatment = pipe_rf_t.predict_proba(X_test_treatment)[:,1]\n",
    "precision, recall, thresholds = precision_recall_curve(y_test_treatment, y_scores_treatment)\n",
    "print(\"auc for RF-SMOTE: \"+str(auc(recall, precision)))\n",
    "\n",
    "## test on control_group\n",
    "y_scores_control = pipe_rf_c.predict_proba(X_test_control)[:,1]\n",
    "y_pred_control = pipe_rf_c.predict(X_test_control)\n",
    "#### performance\n",
    "print(\"CONTROL (imbalanced test set)\"+\"-\"*24)\n",
    "print(classification_report(y_test_control, y_pred_control))\n",
    "precision, recall, thresholds = precision_recall_curve(y_test_control, y_scores_control)\n",
    "print(\"auc for RF-SMOTE: \"+str(auc(recall, precision)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0aa92b7c-c474-4999-b2c8-091f2283bccd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "#sns.lineplot(x=, y=metrics.roc_curve(y_test_treatment, y_scores_treatment))\n",
    "print(metrics.roc_auc_score(y_test_treatment, y_scores_treatment))\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test_treatment, y_scores_treatment)\n",
    "\n",
    "sns.lineplot(x=fpr, y=tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1687398b-515d-4c57-9510-bc84194491c5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### Take Rates vs. Propensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fb0e7889-7b00-48aa-bf11-9e53f55f381d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# plotting actual vs predicted take rates\n",
    "prob_true, prob_pred = calibration_curve(y_test_treatment, y_scores_treatment, n_bins=10)\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "sns.lineplot(x=prob_pred, y=prob_true, color=\"red\", ax=ax1)\n",
    "sns.histplot(y_scores_treatment, stat=\"probability\", color='blue', alpha=0.4, ax=ax2, bins=10)\n",
    "\n",
    "ax1.set_xlabel(\"predicted propensity to respond to a discount\")\n",
    "ax1.set_ylabel(\"actual return rate\")\n",
    "ax2.set_ylabel(\"% of users\")\n",
    "plt.title(\"Predicted vs. Actual Propensities - Treatment Group\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2e3432f7-13b7-4332-bf3c-b22563cab87f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# plotting actual vs predicted take rates\n",
    "prob_true, prob_pred = calibration_curve(y_test_control, y_scores_control, n_bins=10)\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "sns.lineplot(x=prob_pred, y=prob_true, color=\"red\", ax=ax1)\n",
    "sns.histplot(y_scores_control, stat=\"probability\", color='blue', alpha=0.4, ax=ax2, bins=10)\n",
    "\n",
    "ax1.set_xlabel(\"predicted propensity to return without a discount\")\n",
    "ax1.set_ylabel(\"actual return rate\")\n",
    "ax2.set_ylabel(\"% of users\")\n",
    "plt.title(\"Predicted vs. Actual Propensities - Control Group\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7ea78cb8-67ed-4ad3-a18a-4283848f4f58",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### Distribution of Propensities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "26ea1821-25f1-42f1-b01a-c804ed9312f1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# joining back to y_test to X_test and append model predictions\n",
    "y_scores_TR = pipe_rf_t.predict_proba(X_test)[:,1]\n",
    "y_scores_CR = pipe_rf_c.predict_proba(X_test)[:,1]\n",
    "\n",
    "joined_test_set = X_test_all_col.join(y_test_TR).join(y_test_CR)\n",
    "joined_test_set[\"propensity_TR\"] = y_scores_TR.tolist()\n",
    "joined_test_set[\"propensity_CR\"] = y_scores_CR.tolist()\n",
    "joined_test_set[\"propensity_TN\"] = 1-joined_test_set[\"propensity_TR\"]\n",
    "joined_test_set[\"propensity_CN\"] = 1-joined_test_set[\"propensity_CR\"]\n",
    "joined_test_set[\"uplift_score\"] = joined_test_set[\"propensity_TR\"] + joined_test_set[\"propensity_CN\"] - joined_test_set[\"propensity_TN\"] - joined_test_set[\"propensity_CR\"]\n",
    "joined_test_set['uplift_score_bin'] = pd.qcut(joined_test_set[\"uplift_score\"], q=5, precision=0, labels=[5,4,3,2,1])\n",
    "joined_test_set['propensity_TR_bin'] = pd.qcut(joined_test_set[\"propensity_TR\"], q=5, precision=0, labels=[5,4,3,2,1])\n",
    "joined_test_set['propensity_CN_bin'] = pd.qcut(joined_test_set[\"propensity_CN\"], q=5, precision=0, labels=[5,4,3,2,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b89bbffd-2f28-4459-b73c-a77d2945b43e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sns.histplot(joined_test_set[\"uplift_score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ffce2887-7367-436c-8af4-c7c1bd543b3a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Scoring hold out users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "62f32578-fca8-4b44-acc7-c0770a0a760a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### Pulling features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a1bd6f94-47d9-4023-8fbc-53fe62e7fc8c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# pull raw data from data warehouse\n",
    "df_users_to_score = get_user_cohort(cohort=USER_COHORT, \n",
    "                                    country_code=COUNTRY_CODE, \n",
    "                                    subscription_type=SUBSCRIPTION_TYPE, \n",
    "                                    begin_date=SIGNUP_DATE,\n",
    "                                    end_date=SIGNUP_DATE).alias(\"users\")\n",
    "\n",
    "df_engagement_features_to_score = get_engagement_features(USER_COHORT,SIGNUP_DATE,SIGNUP_DATE).alias(\"engagement\")\n",
    "\n",
    "df_event_features_to_score = get_event_features(USER_COHORT,SIGNUP_DATE,SIGNUP_DATE).alias(\"events\")\n",
    "\n",
    "# join resulting dataframes\n",
    "df_all_to_score = df_users_to_score \\\n",
    "  .join(df_engagement_features_to_score, how=\"left\", on=[\"hs_user_id\",\"signup_date\"]) \\\n",
    "  .join(df_event_features_to_score, how=\"left\", on=[\"hs_user_id\",\"signup_date\"]) \\\n",
    "  .withColumn(\"plan_renewal_term_months_c\", F.expr(\"CASE WHEN plan_renewal_term_months = 1 THEN 'monthly' \" +\n",
    "                                                        \"WHEN plan_renewal_term_months = 12 THEN 'annual' \" +\n",
    "                                                        \"ELSE 'other' END\")) \\\n",
    "  .withColumn(\"renewal_c\", F.expr(\"CASE WHEN renewal_count > 0 THEN 'returning' ELSE 'new' END\")) \\\n",
    "  .toPandas() \\\n",
    "  .fillna(0)\n",
    "df_all_to_score[\"max_discount_offered_c\"] = 20\n",
    "df_all_to_score[\"signup_date\"] = pd.to_datetime(df_all_to_score[\"signup_date\"])\n",
    "df_all_to_score[\"dt\"] = pd.to_datetime(df_all_to_score[\"dt\"])\n",
    "\n",
    "# filter on 7 and 14 day free trial users \n",
    "df_all_to_score = df_all_to_score.loc[(df_all_to_score[\"free_trial_days\"]==7)|(df_all_to_score[\"free_trial_days\"]==14)].reset_index(drop=True)\n",
    "\n",
    "# aggregating daily features to weeks\n",
    "for i in [ i[5:] for i in df_all_to_score.filter(like='day0').columns if 'distinct' not in i ]:\n",
    "  df_all_to_score = aggregate_into_weeks(df_all_to_score,1,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "961c231a-9385-4258-98c6-1bf80617c730",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X_score = df_all_to_score[X_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6316a4cf-b53c-48af-9456-ce56005671e4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### Scoring users and appending to feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4900df4c-08eb-4b2f-98a0-eb3bc6304d52",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# joining back to y_test to X_test and append model predictions\n",
    "df_all_to_score[\"propensity_TR\"] = pipe_rf_t.predict_proba(X_score)[:,1].tolist()\n",
    "df_all_to_score[\"propensity_CR\"] = pipe_rf_c.predict_proba(X_score)[:,1].tolist()\n",
    "df_all_to_score[\"propensity_TN\"] = 1-df_all_to_score[\"propensity_TR\"]\n",
    "df_all_to_score[\"propensity_CN\"] = 1-df_all_to_score[\"propensity_CR\"]\n",
    "df_all_to_score[\"uplift_score\"] = df_all_to_score[\"propensity_TR\"] + df_all_to_score[\"propensity_CN\"] - df_all_to_score[\"propensity_TN\"] - df_all_to_score[\"propensity_CR\"]\n",
    "df_all_to_score['uplift_score_bin'] = pd.qcut(df_all_to_score[\"uplift_score\"],   q=10, precision=0, labels=[10,9,8,7,6,5,4,3,2,1])\n",
    "df_all_to_score['propensity_TR_bin'] = pd.qcut(df_all_to_score[\"propensity_TR\"], q=10, precision=0, labels=[10,9,8,7,6,5,4,3,2,1])\n",
    "df_all_to_score['propensity_CN_bin'] = pd.qcut(df_all_to_score[\"propensity_CN\"], q=10, precision=0, labels=[10,9,8,7,6,5,4,3,2,1])\n",
    "df_all_to_score[\"signup_date\"] = [str(i.date()) for i in df_all_to_score[\"signup_date\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6c593760-805b-4873-9972-11fac2301730",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## Convert into Spark DataFrame\n",
    "spark_df = spark.createDataFrame(df_all_to_score[[\"hs_user_id\",\n",
    "                                                  \"signup_date\",\n",
    "                                                  \"propensity_TR\",\n",
    "                                                  \"propensity_CR\",\n",
    "                                                  \"propensity_TN\",\n",
    "                                                  \"propensity_CN\",\n",
    "                                                  \"uplift_score\",\n",
    "                                                  \"uplift_score_bin\"\n",
    "                                                 ]])\n",
    "## Write to databricks\n",
    "spark_df \\\n",
    "  .write \\\n",
    "  .mode('append') \\\n",
    "  .option(\"mergeSchema\", \"true\") \\\n",
    "  .saveAsTable(\"ds_staging.lifecycle_models__ftdo_propensity_scores\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "staging__1.0-ftdo-lifecycle-model",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
