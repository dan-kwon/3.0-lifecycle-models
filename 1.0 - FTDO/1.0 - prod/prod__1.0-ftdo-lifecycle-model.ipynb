{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f9d05772-081c-40ae-837e-d61cae821430",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Lifecycle Model - FT Conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "43acb452-74c7-4b1f-ba34-15cd574e0031",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Libraries / Global Vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b72087d8-b93c-46fe-ab61-a2043e128ec3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# general use\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "#from chaya_ai.chaya_ai import tracker \n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "# data retrieval / prep\n",
    "from datetime import datetime\n",
    "from pyspark.sql import functions as F\n",
    "from sklearn.utils import resample\n",
    "from imblearn.over_sampling import SMOTENC, RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# pipeline\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn import set_config\n",
    "\n",
    "# feature processing and selection\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, PolynomialFeatures\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectFromModel, SelectKBest, chi2\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# training\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "# validation\n",
    "from sklearn.calibration import CalibrationDisplay, calibration_curve\n",
    "from sklearn.metrics import classification_report, PrecisionRecallDisplay\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "# matching / evaluation\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy import stats\n",
    "import random\n",
    "\n",
    "# global vars\n",
    "today = datetime.today()\n",
    "random_state = 1234"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6d8fc7cf-59b2-4483-9cb8-7b4b92a816b5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Loading additional UDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1ee758e8-af64-4c22-8df0-f84a5487f4bb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run \"./udf/prod__lifecycle-features\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "86df7752-648c-4892-8e17-9ff3317bf2f4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run \"./udf/prod__lifecycle-target-events\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ace0d849-bdd3-4a7c-8f86-7a2a69d8da3e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run \"./udf/prod__lifecycle-user-cohorts\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "36690a71-6e48-46fa-a799-27c7339e1a69",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Creating widgets and assigning parameter values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e337ef15-c2fd-4eba-9b7c-c5edb2653b64",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# widget choices / defaul values\n",
    "query = \"\"\"\n",
    "  select max(signup_date)\n",
    "  from ds_staging.features__engagement_first_7_days\n",
    "  \"\"\"\n",
    "\n",
    "list_of_available_dates = [str(i.date()) for i in pd.to_datetime(spark.sql(query).toPandas().values[:,0])]\n",
    "\n",
    "DATE_7DAYS_AGO = str(today.date() - relativedelta(days=7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b5e405ae-bb07-4956-8c34-8b6198c1c906",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.widgets.removeAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "123b9e92-2aa2-4063-9dc5-63888845e820",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# define date range\n",
    "dbutils.widgets.text(name=\"signup_date\",\n",
    "                         defaultValue=max(list_of_available_dates),\n",
    "                         label=\"Signup Date\")\n",
    "# define cohort\n",
    "dbutils.widgets.text(name=\"user_cohort\", \n",
    "                         defaultValue=\"free trial drop out\", \n",
    "                         label=\"User Cohort\")\n",
    "# define event of interest\n",
    "dbutils.widgets.text(name=\"target_event\", \n",
    "                     defaultValue=\"converted free trial drop out\",\n",
    "                     label=\"Event of Interest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "227f6937-f2f4-466b-8121-51da1a0a6ec4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "USER_COHORT = dbutils.widgets.get(\"user_cohort\")\n",
    "TARGET_EVENT = dbutils.widgets.get(\"target_event\")\n",
    "SUBSCRIPTION_TYPE = 'b2c'\n",
    "COUNTRY_CODE = 'us'\n",
    "HORIZON_DAYS = 42\n",
    "\n",
    "# date parameters\n",
    "SIGNUP_DATE  = dbutils.widgets.get(\"signup_date\")\n",
    "TEST_END_DATE   = pd.to_datetime(dbutils.widgets.get(\"signup_date\")).date()-pd.to_timedelta(HORIZON_DAYS+1, unit='d')\n",
    "TEST_BEGIN_DATE = pd.to_datetime(dbutils.widgets.get(\"signup_date\")).date()-pd.to_timedelta(HORIZON_DAYS+28, unit='d')\n",
    "TRAIN_END_DATE   = pd.to_datetime(dbutils.widgets.get(\"signup_date\")).date()-pd.to_timedelta(HORIZON_DAYS+29, unit='d')\n",
    "TRAIN_BEGIN_DATE = pd.to_datetime(dbutils.widgets.get(\"signup_date\")).date()-pd.to_timedelta(HORIZON_DAYS+29+365, unit='d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8d87f9ea-5b94-4904-96b2-77949221b9d9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ac6e062d-fa71-42c8-a927-0b49b4225f9f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# pull raw data from data warehouse\n",
    "df_users = get_user_cohort(cohort=USER_COHORT, \n",
    "                           country_code=COUNTRY_CODE, \n",
    "                           subscription_type=SUBSCRIPTION_TYPE, \n",
    "                           begin_date=TRAIN_BEGIN_DATE,\n",
    "                           end_date=TEST_END_DATE).alias(\"users\")\n",
    "\n",
    "df_engagement_features = get_engagement_features(USER_COHORT,TRAIN_BEGIN_DATE,TEST_END_DATE).alias(\"engagement\")\n",
    "\n",
    "df_event_features = get_event_features(USER_COHORT,TRAIN_BEGIN_DATE,TEST_END_DATE).alias(\"events\")\n",
    "\n",
    "df_targets = get_target_event(cohort=USER_COHORT,\n",
    "                              country_code=COUNTRY_CODE, \n",
    "                              subscription_type=SUBSCRIPTION_TYPE,\n",
    "                              begin_date=TRAIN_BEGIN_DATE,\n",
    "                              end_date=TEST_END_DATE,\n",
    "                              horizon_days=HORIZON_DAYS).alias(\"target\")\n",
    "\n",
    "# join resulting dataframes\n",
    "df_all = df_users \\\n",
    "  .join(df_targets, how=\"inner\", on=[\"hs_user_id\",\"signup_date\"]) \\\n",
    "  .join(df_engagement_features, how=\"left\", on=[\"hs_user_id\",\"signup_date\"]) \\\n",
    "  .join(df_event_features, how=\"left\", on=[\"hs_user_id\",\"signup_date\"]) \\\n",
    "  .withColumn(\"plan_renewal_term_months_c\", F.expr(\"CASE WHEN plan_renewal_term_months = 1 THEN 'monthly' \" +\n",
    "                                                        \"WHEN plan_renewal_term_months = 12 THEN 'annual' \" +\n",
    "                                                        \"ELSE 'other' END\")) \\\n",
    "  .withColumn(\"max_discount_offered_c\", F.expr(\"CASE WHEN num_offers_40 > 0 THEN 40 \" +\n",
    "                                               \"WHEN num_offers_30 > 0 THEN 30 \" +\n",
    "                                               \"WHEN num_offers_20 > 0 THEN 20 \" +\n",
    "                                               \"ELSE 0 END\")) \\\n",
    "  .withColumn(\"renewal_c\", F.expr(\"CASE WHEN renewal_count > 0 THEN 'returning' ELSE 'new' END\")) \\\n",
    "  .toPandas() \\\n",
    "  .fillna(0)\n",
    "\n",
    "df_all[\"signup_date\"] = pd.to_datetime(df_all[\"signup_date\"])\n",
    "df_all[\"dt\"] = pd.to_datetime(df_all[\"dt\"])\n",
    "\n",
    "# filter on 7 and 14 day free trial users \n",
    "df_all = df_all.loc[(df_all[\"free_trial_days\"]==7)|(df_all[\"free_trial_days\"]==14)].reset_index(drop=True)\n",
    "\n",
    "# one hot encode experiment group\n",
    "enc = OneHotEncoder()\n",
    "df_enc_experiment_group = pd.DataFrame(enc.fit_transform(df_all[[\"experiment_group\"]]).toarray())\n",
    "df_enc_experiment_group.columns = enc.get_feature_names_out()\n",
    "df_all = df_all.join(df_enc_experiment_group)\n",
    "\n",
    "# aggregating daily features to weeks\n",
    "def aggregate_into_weeks(df, week_num, feature_name):\n",
    "  df[f\"week{week_num}_{feature_name}\"] = df[f\"day{range(week_num*7-7, week_num*7)[0]}_{feature_name}\"] + \\\n",
    "                                         df[f\"day{range(week_num*7-7, week_num*7)[1]}_{feature_name}\"] + \\\n",
    "                                         df[f\"day{range(week_num*7-7, week_num*7)[2]}_{feature_name}\"] + \\\n",
    "                                         df[f\"day{range(week_num*7-7, week_num*7)[3]}_{feature_name}\"] + \\\n",
    "                                         df[f\"day{range(week_num*7-7, week_num*7)[4]}_{feature_name}\"] + \\\n",
    "                                         df[f\"day{range(week_num*7-7, week_num*7)[5]}_{feature_name}\"] + \\\n",
    "                                         df[f\"day{range(week_num*7-7, week_num*7)[6]}_{feature_name}\"]\n",
    "  return df\n",
    "for i in [ i[5:] for i in df_all.filter(like='day0').columns if 'distinct' not in i ]:\n",
    "  df_all = aggregate_into_weeks(df_all,1,i)\n",
    "   \n",
    "# split treatment and control groups\n",
    "df_treatment = df_all.loc[(df_all[\"experiment_group\"]==\"TN\")|(df_all[\"experiment_group\"]==\"TR\")]\n",
    "df_control   = df_all.loc[(df_all[\"experiment_group\"]==\"CN\")|(df_all[\"experiment_group\"]==\"CR\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d59d4288-d8c0-460d-95f8-a742f5108395",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# train sets\n",
    "X_train_treatment_all_col = df_treatment[df_treatment[\"signup_date\"] <= str(TRAIN_END_DATE)] \\\n",
    "  .drop([\"experiment_group\",\n",
    "         \"experiment_group_TR\",\n",
    "         \"experiment_group_TN\",\n",
    "         \"experiment_group_CR\",\n",
    "         \"experiment_group_CN\"], \n",
    "        axis=1)\n",
    "y_train_treatment = df_treatment.loc[df_treatment[\"signup_date\"] <= str(TRAIN_END_DATE),\"experiment_group_TR\"]\n",
    "\n",
    "X_train_control_all_col = df_control[df_control[\"signup_date\"] <= str(TRAIN_END_DATE)] \\\n",
    "  .drop([\"experiment_group\",\n",
    "         \"experiment_group_TR\",\n",
    "         \"experiment_group_TN\",\n",
    "         \"experiment_group_CR\",\n",
    "         \"experiment_group_CN\"], \n",
    "        axis=1)\n",
    "y_train_control = df_control.loc[df_control[\"signup_date\"] <= str(TRAIN_END_DATE),\"experiment_group_CR\"]\n",
    "\n",
    "# test sets\n",
    "X_test_all_col = df_all[df_all[\"signup_date\"] > str(TRAIN_END_DATE)] \\\n",
    "  .drop([\"experiment_group\",\n",
    "         \"experiment_group_TR\",\n",
    "         \"experiment_group_TN\",\n",
    "         \"experiment_group_CR\",\n",
    "         \"experiment_group_CN\"], \n",
    "        axis=1)\n",
    "X_test_treatment_all_col = df_treatment.loc[df_treatment[\"signup_date\"] > str(TRAIN_END_DATE)] \\\n",
    "  .drop([\"experiment_group\",\n",
    "         \"experiment_group_TR\",\n",
    "         \"experiment_group_TN\",\n",
    "         \"experiment_group_CR\",\n",
    "         \"experiment_group_CN\"], \n",
    "        axis=1)\n",
    "X_test_control_all_col = df_control[df_control[\"signup_date\"] > str(TRAIN_END_DATE)] \\\n",
    "  .drop([\"experiment_group\",\n",
    "         \"experiment_group_TR\",\n",
    "         \"experiment_group_TN\",\n",
    "         \"experiment_group_CR\",\n",
    "         \"experiment_group_CN\"], \n",
    "        axis=1)\n",
    "y_test_TR = df_all.loc[df_all[\"signup_date\"] > str(TRAIN_END_DATE), \"experiment_group_TR\"]\n",
    "y_test_CR = df_all.loc[df_all[\"signup_date\"] > str(TRAIN_END_DATE), \"experiment_group_CR\"]\n",
    "y_test_treatment = df_treatment.loc[df_treatment[\"signup_date\"] > str(TRAIN_END_DATE), \"experiment_group_TR\"]\n",
    "y_test_control = df_control.loc[df_control[\"signup_date\"] > str(TRAIN_END_DATE), \"experiment_group_CR\"]\n",
    "\n",
    "# final train sets\n",
    "X_final_train_treatment_all_col = df_treatment[df_treatment[\"signup_date\"] <= str(TEST_END_DATE)] \\\n",
    "  .drop([\"experiment_group\",\n",
    "         \"experiment_group_TR\",\n",
    "         \"experiment_group_TN\",\n",
    "         \"experiment_group_CR\",\n",
    "         \"experiment_group_CN\"], \n",
    "        axis=1)\n",
    "y_final_train_treatment = df_treatment.loc[df_treatment[\"signup_date\"] <= str(TEST_END_DATE),\"experiment_group_TR\"]\n",
    "\n",
    "X_final_train_control_all_col = df_control[df_control[\"signup_date\"] <= str(TEST_END_DATE)] \\\n",
    "  .drop([\"experiment_group\",\n",
    "         \"experiment_group_TR\",\n",
    "         \"experiment_group_TN\",\n",
    "         \"experiment_group_CR\",\n",
    "         \"experiment_group_CN\"], \n",
    "        axis=1)\n",
    "y_final_train_control = df_control.loc[df_control[\"signup_date\"] <= str(TEST_END_DATE),\"experiment_group_CR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f0590d7a-0af9-44f8-a24c-88b093f35ef8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# specify categorical column names\n",
    "categorical_col = [\"plan_renewal_term_months_c\", \"subscription_platform\", \"renewal_c\"] #, \"num_offers_20\", \"num_offers_30\", \"num_offers_40\"]\n",
    "\n",
    "# get list of categorical + numeric features to include in model\n",
    "X_col = categorical_col.copy()\n",
    "X_col += [i for i in X_train_treatment_all_col.columns if 'week1' in i or \n",
    "                                                          'free_trial_days' in i or\n",
    "                                                          'max_discount' in i or\n",
    "                                                          'renewal_count' in i or\n",
    "                                                          'free_trial_days' in i]\n",
    "X_col.sort()\n",
    "X_train_treatment       = X_train_treatment_all_col[X_col]\n",
    "X_train_control         = X_train_control_all_col[X_col]\n",
    "X_test_treatment        = X_test_treatment_all_col[X_col]\n",
    "X_test_control          = X_test_control_all_col[X_col]\n",
    "X_final_train_treatment = X_final_train_treatment_all_col[X_col]\n",
    "X_final_train_control   = X_final_train_control_all_col[X_col]\n",
    "\n",
    "X_test                  = X_test_all_col[X_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fb6ed236-b1c3-418f-a660-ea55aed043bd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# SMOTE oversampling the minority class\n",
    "smote_oversample = SMOTENC(random_state=random_state, categorical_features=[X_train_treatment.columns.get_loc(col) for col in categorical_col])\n",
    "X_train_treatment, y_train_treatment = smote_oversample.fit_resample(X_train_treatment, y_train_treatment)\n",
    "X_train_control,   y_train_control   = smote_oversample.fit_resample(X_train_control,   y_train_control)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bacaede3-1899-46af-a879-6274503ebca4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4f9abca7-1546-4443-aa87-b279526a4784",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "numeric_preprocessor = Pipeline(\n",
    "    steps=[\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"pca\", PCA()),\n",
    "        (\"variance threshold\", VarianceThreshold())\n",
    "    ])\n",
    "\n",
    "categorical_preprocessor = Pipeline(\n",
    "    steps=[\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "    ])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        (\"categorical\", categorical_preprocessor, categorical_col),\n",
    "        (\"numerical\", numeric_preprocessor, list(set(X_col) - set(categorical_col))),\n",
    "    ])\n",
    "\n",
    "pipe_rf_t = Pipeline(\n",
    "    steps=[(\"preprocessor\", preprocessor),\n",
    "           (\"interactions\", PolynomialFeatures(interaction_only=False)),\n",
    "           ('classifier', CalibratedClassifierCV(base_estimator=RandomForestClassifier(min_samples_split=0.03, n_estimators = 120), cv=8, method='sigmoid', n_jobs=-2))])\n",
    "\n",
    "pipe_rf_c = Pipeline(\n",
    "    steps=[(\"preprocessor\", preprocessor),\n",
    "           (\"interactions\", PolynomialFeatures(interaction_only=False)),\n",
    "           (\"classifier\", CalibratedClassifierCV(base_estimator=RandomForestClassifier(min_samples_split=0.03, n_estimators = 120), cv=8, method='sigmoid', n_jobs=-2))])\n",
    "\n",
    "# grid search takes ~30 min and doesn't result in a meaningful increase in performance so commenting out for now\n",
    "#pipe_rf = Pipeline(\n",
    "#    steps=[(\"preprocessor\", preprocessor),\n",
    "#           (\"interactions\", PolynomialFeatures(interaction_only=False)),\n",
    "#           ('classifier', RandomForestClassifier())\n",
    "#          ])\n",
    "#param_grid_rf = {\n",
    "#  \"classifier__n_estimators\": [200, 400, 600],\n",
    "#  \"classifier__max_depth\": [6, 8, 10, 12]\n",
    "#}\n",
    "#grid_search_rf = GridSearchCV(pipe_rf, param_grid_rf, n_jobs=20, scoring='f1_micro')\n",
    "#calibrated_clf = CalibratedClassifierCV(grid_search_rf.best_estimator_)\n",
    "#calibrated_clf.fit(X_train_smote, y_train_smote.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ee6beabb-3a8b-499f-9640-6cbce85f62f2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Training Model\n",
    "\n",
    "NOTE: This section should be commented out when deployed in production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f29d5467-7e99-4d76-9ede-9981e7d645a1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## train on oversampled training set\n",
    "#set_config(display=\"diagram\")\n",
    "#\n",
    "## active models\n",
    "#pipe_rf_t.fit(X_train_treatment, y_train_treatment.values.ravel())\n",
    "#pipe_rf_c.fit(X_train_control,   y_train_control.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9c13e72e-47cc-4053-85f1-7f387f59bd36",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Testing Model\n",
    "\n",
    "NOTE: This section should be commented out when deployed in production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1c50a7e8-dd28-419d-8106-edd170a8716a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## test on treatment_group\n",
    "#y_scores_treatment = pipe_rf_t.predict_proba(X_test_treatment)[:,1]\n",
    "#y_pred_treatment = pipe_rf_t.predict(X_test_treatment)\n",
    "##### performance\n",
    "#print(\"TREATMENT (imbalanced test set)\"+\"-\"*22)\n",
    "#print(classification_report(y_test_treatment, y_pred_treatment))\n",
    "#y_scores_treatment = pipe_rf_t.predict_proba(X_test_treatment)[:,1]\n",
    "#precision, recall, thresholds = precision_recall_curve(y_test_treatment, y_scores_treatment)\n",
    "#print(\"auc for RF-SMOTE: \"+str(auc(recall, precision)))\n",
    "#\n",
    "## test on control_group\n",
    "#y_scores_control = pipe_rf_c.predict_proba(X_test_control)[:,1]\n",
    "#y_pred_control = pipe_rf_c.predict(X_test_control)\n",
    "##### performance\n",
    "#print(\"CONTROL (imbalanced test set)\"+\"-\"*24)\n",
    "#print(classification_report(y_test_control, y_pred_control))\n",
    "#precision, recall, thresholds = precision_recall_curve(y_test_control, y_scores_control)\n",
    "#print(\"auc for RF-SMOTE: \"+str(auc(recall, precision)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "658a6d68-75b2-40f2-94a1-f88a56d94f08",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#from sklearn import metrics\n",
    "#\n",
    "##sns.lineplot(x=, y=metrics.roc_curve(y_test_treatment, y_scores_treatment))\n",
    "#print(metrics.roc_auc_score(y_test_treatment, y_scores_treatment))\n",
    "#fpr, tpr, thresholds = metrics.roc_curve(y_test_treatment, y_scores_treatment)\n",
    "#\n",
    "#sns.lineplot(x=fpr, y=tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f5ebf45e-6d81-4f6b-a433-e1e8d7b0797e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### Take Rates vs. Propensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "00f3c385-c301-4404-8007-fd6a3eb014b3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## plotting actual vs predicted take rates\n",
    "#prob_true, prob_pred = calibration_curve(y_test_treatment, y_scores_treatment, n_bins=10)\n",
    "#\n",
    "#fig, ax1 = plt.subplots()\n",
    "#ax2 = ax1.twinx()\n",
    "#\n",
    "#sns.lineplot(x=prob_pred, y=prob_true, color=\"red\", ax=ax1)\n",
    "#sns.histplot(y_scores_treatment, stat=\"probability\", color='blue', alpha=0.4, ax=ax2, bins=10)\n",
    "#\n",
    "#ax1.set_xlabel(\"predicted propensity to respond to a discount\")\n",
    "#ax1.set_ylabel(\"actual return rate\")\n",
    "#ax2.set_ylabel(\"% of users\")\n",
    "#plt.title(\"Predicted vs. Actual Propensities - Treatment Group\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4d4cd877-a3c5-4ac5-94b5-c1767e75de54",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## plotting actual vs predicted take rates\n",
    "#prob_true, prob_pred = calibration_curve(y_test_control, y_scores_control, n_bins=10)\n",
    "#\n",
    "#fig, ax1 = plt.subplots()\n",
    "#ax2 = ax1.twinx()\n",
    "#\n",
    "#sns.lineplot(x=prob_pred, y=prob_true, color=\"red\", ax=ax1)\n",
    "#sns.histplot(y_scores_control, stat=\"probability\", color='blue', alpha=0.4, ax=ax2, bins=10)\n",
    "#\n",
    "#ax1.set_xlabel(\"predicted propensity to return without a discount\")\n",
    "#ax1.set_ylabel(\"actual return rate\")\n",
    "#ax2.set_ylabel(\"% of users\")\n",
    "#plt.title(\"Predicted vs. Actual Propensities - Control Group\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6d3a25fd-8bef-47eb-bb15-fb294d867ed1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### Distribution of Propensities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "05b9e994-3fbc-4ab6-ac64-c541f16f88d7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## joining back to y_test to X_test and append model predictions\n",
    "#y_scores_TR = pipe_rf_t.predict_proba(X_test)[:,1]\n",
    "#y_scores_CR = pipe_rf_c.predict_proba(X_test)[:,1]\n",
    "#\n",
    "#joined_test_set = X_test_all_col.join(y_test_TR).join(y_test_CR)\n",
    "#joined_test_set[\"propensity_TR\"] = y_scores_TR.tolist()\n",
    "#joined_test_set[\"propensity_CR\"] = y_scores_CR.tolist()\n",
    "#joined_test_set[\"propensity_TN\"] = 1-joined_test_set[\"propensity_TR\"]\n",
    "#joined_test_set[\"propensity_CN\"] = 1-joined_test_set[\"propensity_CR\"]\n",
    "#joined_test_set[\"uplift_score\"] = joined_test_set[\"propensity_TR\"] + joined_test_set[\"propensity_CN\"] - joined_test_set[\"propensity_TN\"] - joined_test_set[\"propensity_CR\"]\n",
    "#joined_test_set['uplift_score_bin'] = pd.qcut(joined_test_set[\"uplift_score\"], q=10, precision=0, labels=[1,2,3,4,5,6,7,8,9,10])\n",
    "#joined_test_set['propensity_TR_bin'] = pd.qcut(joined_test_set[\"propensity_TR\"], q=10, precision=0, labels=[1,2,3,4,5,6,7,8,9,10])\n",
    "#joined_test_set['propensity_CN_bin'] = pd.qcut(joined_test_set[\"propensity_CN\"], q=10, precision=0, labels=[1,2,3,4,5,6,7,8,9,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c6e9d76e-6a22-4757-8e26-034fd6701c9a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#sns.histplot(joined_test_set[\"uplift_score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f3d46b7e-c66b-458e-9462-486d19012701",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Scoring hold out users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "99d3aecc-b24e-468a-9cb5-c7028d42b392",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### Pulling features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b3f40b85-4cb5-439d-8810-ec748d49e2bb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# pull raw data from data warehouse\n",
    "df_users_to_score = get_user_cohort(cohort=USER_COHORT, \n",
    "                                    country_code=COUNTRY_CODE, \n",
    "                                    subscription_type=SUBSCRIPTION_TYPE, \n",
    "                                    begin_date=SIGNUP_DATE,\n",
    "                                    end_date=SIGNUP_DATE).alias(\"users\")\n",
    "\n",
    "df_engagement_features_to_score = get_engagement_features(USER_COHORT,SIGNUP_DATE,SIGNUP_DATE).alias(\"engagement\")\n",
    "\n",
    "df_event_features_to_score = get_event_features(USER_COHORT,SIGNUP_DATE,SIGNUP_DATE).alias(\"events\")\n",
    "\n",
    "# join resulting dataframes\n",
    "df_all_to_score = df_users_to_score \\\n",
    "  .join(df_engagement_features_to_score, how=\"left\", on=[\"hs_user_id\",\"signup_date\"]) \\\n",
    "  .join(df_event_features_to_score, how=\"left\", on=[\"hs_user_id\",\"signup_date\"]) \\\n",
    "  .withColumn(\"plan_renewal_term_months_c\", F.expr(\"CASE WHEN plan_renewal_term_months = 1 THEN 'monthly' \" +\n",
    "                                                        \"WHEN plan_renewal_term_months = 12 THEN 'annual' \" +\n",
    "                                                        \"ELSE 'other' END\")) \\\n",
    "  .withColumn(\"renewal_c\", F.expr(\"CASE WHEN renewal_count > 0 THEN 'returning' ELSE 'new' END\")) \\\n",
    "  .toPandas() \\\n",
    "  .fillna(0)\n",
    "df_all_to_score[\"max_discount_offered_c\"] = 20\n",
    "df_all_to_score[\"signup_date\"] = pd.to_datetime(df_all_to_score[\"signup_date\"])\n",
    "df_all_to_score[\"dt\"] = pd.to_datetime(df_all_to_score[\"dt\"])\n",
    "\n",
    "# filter on 7 and 14 day free trial users \n",
    "# df_all_to_score = df_all_to_score.loc[(df_all_to_score[\"free_trial_days\"]==7)|(df_all_to_score[\"free_trial_days\"]==14)].reset_index(drop=True)\n",
    "\n",
    "# aggregating daily features to weeks\n",
    "for i in [ i[5:] for i in df_all_to_score.filter(like='day0').columns if 'distinct' not in i ]:\n",
    "  df_all_to_score = aggregate_into_weeks(df_all_to_score,1,i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "421d4327-191c-4a65-854a-65ed52316743",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### Scoring users and appending to feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "105dd725-0e9d-4a12-9b91-32982e920f1b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# training final mode on final training set\n",
    "set_config(display=\"diagram\")\n",
    "pipe_rf_t.fit(X_final_train_treatment, y_final_train_treatment.values.ravel())\n",
    "pipe_rf_c.fit(X_final_train_control,   y_final_train_control.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ea3b3045-f3ea-4d63-b0fa-7a320c98f6d9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X_score = df_all_to_score[X_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8390f50b-0029-43ba-9398-90d02877e701",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# joining back to y_test to X_test and append model predictions\n",
    "df_all_to_score[\"propensity_TR\"] = pipe_rf_t.predict_proba(X_score)[:,1].tolist()\n",
    "df_all_to_score[\"propensity_CR\"] = pipe_rf_c.predict_proba(X_score)[:,1].tolist()\n",
    "df_all_to_score[\"propensity_TN\"] = 1-df_all_to_score[\"propensity_TR\"]\n",
    "df_all_to_score[\"propensity_CN\"] = 1-df_all_to_score[\"propensity_CR\"]\n",
    "df_all_to_score[\"uplift_score\"] = df_all_to_score[\"propensity_TR\"] + df_all_to_score[\"propensity_CN\"] - df_all_to_score[\"propensity_TN\"] - df_all_to_score[\"propensity_CR\"]\n",
    "df_all_to_score['uplift_score_bin'] = pd.qcut(df_all_to_score[\"uplift_score\"],   q=10, precision=0, labels=[1,2,3,4,5,6,7,8,9,10])\n",
    "df_all_to_score['propensity_TR_bin'] = pd.qcut(df_all_to_score[\"propensity_TR\"], q=10, precision=0, labels=[1,2,3,4,5,6,7,8,9,10])\n",
    "df_all_to_score['propensity_CN_bin'] = pd.qcut(df_all_to_score[\"propensity_CN\"], q=10, precision=0, labels=[1,2,3,4,5,6,7,8,9,10])\n",
    "df_all_to_score[\"signup_date\"] = [str(i.date()) for i in df_all_to_score[\"signup_date\"]]\n",
    "df_all_to_score[\"run_date\"] = today.date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "900a3f9b-9554-4512-9319-97d22f28e323",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## Convert into Spark DataFrame\n",
    "spark_df = spark.createDataFrame(df_all_to_score[[\"hs_user_id\",\n",
    "                                                  \"signup_date\",\n",
    "                                                  \"propensity_TR\",\n",
    "                                                  \"propensity_CR\",\n",
    "                                                  \"propensity_TN\",\n",
    "                                                  \"propensity_CN\",\n",
    "                                                  \"uplift_score\",\n",
    "                                                  \"uplift_score_bin\",\n",
    "                                                  \"run_date\"\n",
    "                                                 ]])\n",
    "## Write to databricks\n",
    "spark_df \\\n",
    "  .write \\\n",
    "  .mode('append') \\\n",
    "  .option(\"mergeSchema\", \"true\") \\\n",
    "  .saveAsTable(\"ds_staging.lifecycle_models__ftdo_propensity_scores\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "prod__1.0-ftdo-lifecycle-model",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
